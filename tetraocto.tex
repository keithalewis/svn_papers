\documentclass[11pt,fleqn]{article}
\usepackage{amssymb,amsmath,amsthm,hyperref}
\usepackage{enumerate}

\newcommand{\G}{{\cal G}}
\newcommand{\R}{\mathbb{R}}
\newtheorem{lemma}{Lemma}[section]
\newtheorem{ex}{Excercise}[section]

\title{Counting Faces}
\author{Keith A. Lewis}

\begin{document}
\maketitle

\section{Introduction}
If a regular tetrahedron and a regular octohedron having edges
with the same length are glued together at a face, how many sides
does the resulting polyhedron have?

This was a question on an SAT test and the `correct answer' was
$8 - 1 + 4 - 1 = 10$. A clever applicant with exceptional geometric
intution noticed two pairs of faces were coplanar and that the
answer should be $10 - 2 = 8$. 

It turns out the correct answer is in fact 7, as pointed out by Aharon
Tam when I posed this problem in a course I taught.  In the 19th century
Hermann Grassmann came up with a method of reducing geometric problems
to algebraic calculations. All you need to know to solve this is that
the product of a point with itself is zero. But that leads to 
complications some very smart people have been coming to grasps with
since then.

One of the prettiest results from his idea is the Generalized Stokes theorem
via Elie Cartan \cite{Car???}.
\[
\int_\Omega d\omega = \int_{\partial\Omega} \omega
\]
The integral over a region of a differential is the integral
over the boundary of a form. Although not immediately obvious,
the Fundamental Theorem of Calculus is a special case of
this: \(\int_a^b f'(x)\,dx = f(b) - f(a)\). Here
\(\omega = f(x)\), \(d\omega = f'(x)\,dx\), \(\Omega = [a, b]\)
and \(\partial\Omega\) somehow corresponds to \(b - a\).

\section{Geometry}
Let \(e_1$, $e_2$, $e_3\) be an orthonormal basis in 3-dimensional space.
Take the base of the octohedron to be the vertices \(p_{11} = e_1 + e_2\),
$p_{1-1} = e_1 - e_2$, $p_{-1-1} = -e_1 - e_2$, and $p_{-11} = -e_1 + e_2$.
The two vertices of the pyramids are $p_+ = t e_3$ and $p_- = -te_3$
for some scalar $t$. Since the distance from $p_+$ to, say, $p_{11}$
is 2, we have $1^2 + 1^2 + t^2 = 2^2$ so $t = \sqrt{2}$.

The vertex of a tetrahedron with base $p_{11}$, $p_{1-1}$, and $p_+$
has the form $p = u e_1 + v e_3$ since the $e_2$ coefficent must be 0 by
symmetry. Using the fact that the distance from $p$ to $p_+$ and $p_{11}$
is 2 we have $u^2 + (v - \sqrt{2})^2 = 4$ and $(u - 1)^2 + 1 + (v -
1)^2 = 4$. Subtracting these two equations yields $u = \sqrt{2}v$. This
gives $u = 2$ and $v = \sqrt{2}$. Note
that \(p - p_+\) is parallel to the \(e_1\) axis.

\section{Algebra}
Hermann Grassmann figured out how to prove geometric results using
algebra. Instead of working with vectors, he used points in space.
In modern terminology, his notion of Euclidean space is characterized by a
vector space acting on a set. Given a point in space, a vector translates
it to a new point.

The mathematical notation for that is if \(P\) is a point in Euclidean
space, \(E\), and \(v\) is a vector, then \(P\in E\) is translated
to \(P + v\in E\) and satisfies the condition \(P + (v + w) = (P + v) + w\).
If \(V\) is \(n\)-dimensional and the action is both one-to-one and onto,
then we have \(E\) is \(n\)-dimensional Euclidean space.

Grassmann started with \(E\) and defined vectors to be the difference
of two points. He had to. Vector spaces had not yet been invented.
Euclidean geometry was the tenor of his time. Vector spaces are
a more abstract notion.
His rules were to consider the algebra generated by the points of \(E\)
with the condition \(PQ = 0\) if and only if \(P = Q\) where \(P,Q\in E\). The product of a point with itself is 0. An immediate consequence
is that his (exterior) product is anti-commutative:
\(PQ = -QP\) since \((P + Q)(P + Q) = 0\).

\section{Solution}
The calculations can be a bit tedious, but all this goes back to
Grassmann's contempory George Boole \cite{boole1854} and his insight
that reasoning can be reduced to a calculation. Grassmann was extending
that idea to geometric problems. We now live in a world where
it is commonplace for computers implement these notions.

To hook up vectors to points in Euclidean space an origin needs
to be specified. Let's call the origin \(O\). Using capital letters
for points and lower case for vectors, \(P = O + p\), etc.

A consequence of Grassmann's exterior product is that
\(P_0P_1\cdots P_k = 0\) if and only if there exists
scalars \((t_j)\), not all zero, such that
\(t_0P_0 + t_1P_1 + \cdots + t_kP_k = 0\). (This is called
{\em linear dependence}. His rule that \(PQ = 0\) if and only
if \(P = Q\) is the case \(k = 1\).)

We need this for the case \(k = 3\) where we state it
as \(P_0P_1P_2P_3 = 0\) iff \(P_0\), \(P_1\), \(P_2\),
and \(P_3\) are co-planar.

Now the problem is reduced to a mechanical calculation:

\begin{align*}
PP_+P_{11}P_{-11} &= PP_+(O + e_1 + e_2)(O - e_1 + e_2)\\
    &= PP_+(-Oe_1 + Oe_2 + e_1O + e_1e_2 + e_2O - e_2e_1)\\
	&= P(O + \sqrt{2}e_3)(-2Oe_1 + 2e_1 e_2)\\
	&= P(20e_1e2 - 2\sqrt{2} e_3Oe_1 + 2\sqrt{2} e_3e_1e_2)\\
	&= (O + 2e_1 + \sqrt{2}e_3)
		(2Oe_1e_2 - 2\sqrt{2} Oe_2e_3 + 2\sqrt{2}e_1e_2e_3)\\
	&= (2\sqrt{2}Oe_1e_2e_3 + 2\sqrt{2}e_3Oe_1e_2)\\
	&= 0
\end{align*}

The calculation for \(PP_+P{-1-1}P_{1-1}\) is similar, but it
is obvious from symmetry that the product is zero.

The result the clever SAT student missed but Aharon saw is that 
\(PP_-P_{11}P_{1-1}\) is also zero. Rearranging terms makes
the computation easier:

\begin{align*}
P_{11}P_{1-1}P_-P
	&= P_{11}P_{1-1}(O - \sqrt{2}e_3)(O + 2e_1 + \sqrt{2}e_3)\\
	&= P_{11}P_{1-1}(2Oe_1 + \sqrt{2}Oe_3 - \sqrt{2}e_3O - 2\sqrt{2}e_3e_1)\\
	&= P_{11}(O + e_1 - e_2)(2Oe_1 + 2\sqrt{2}Oe_3 + 2\sqrt{2}e_1e_3)\\
	&= P_{11}(2\sqrt{2}Oe_1e_3 + 2\sqrt{2}e_1Oe_3
		- 2e_2Oe_1 - 2\sqrt{2}e_2Oe_3)\\
	&= (O + e_1 + e_2)(-2Oe_1e_2 + 2\sqrt{2}Oe_2e_3 + 2\sqrt{2}e_1e_2e_3)\\
	&= 2\sqrt{2}Oe_1e_2e_3 + 2\sqrt{2}e_1Oe_2e_3\\
	&= 0
\end{align*}

\end{document}
