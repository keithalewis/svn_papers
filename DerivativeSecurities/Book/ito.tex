\section{Stochastic Calculus}
The standard reference for the It\=o calculus is [1].
These notes just give color and are not a replacement.
An excellent introduction to the more general notion of
stochastic integration is [2], but that is not
covered here.

\subsection{Brownian Motion}
If $(X_t)_{t\ge0}$ is a continuous stochastic process that is stationary
and has independent normally distributed increments then there exist
constants $\mu$, $\sigma\in\R$ with $X_t = \mu t + \sigma B_t$, where
$(B_t)_{t\ge0}$ is standard Brownian motion.

\begin{theorem}{(Relection Principle)}
For any measurable function $f$ and constant $a > 0$,
$$
E[f(B_t)1(\max_{s\le t} B_s > a)]
= E[f(B_t)1(B_t > a)]
+ E[f(2a - B_t)1(B_t > a)]
$$
\end{theorem}
\begin{proof}
Define $T_a = \inf\{t > 0 : B_t > a\}$. The reflection priciple
for Brownian motion states that
$B'_t = B_t$ for $t < T_a$ and $B'_t = 2a - B_t$ for $t > T_a$
is also a Brownian motion.
\begin{eqnarray*}
&&E[f(B_t)1(\max_{s\le t} B_s > a)]\\
&&\quad= E[f(B_t)1(\max_{s\le t} B_s > a, B_t > a)]
+ E[f(B_t)1(\max_{s\le t} B_s > a), B_t < a]\\
&&\quad= E[f(B_t)1(B_t > a)]
+ E[f(B'_t)1(\max_{s\le t} B'_s > a), B'_t < a]\\
&&\quad= E[f(B_t)1(B_t > a)]
+ E[f(2a - B_t)1(\max_{s\le t} B'_s > a), 2a - B_t < a]\\
&&\quad= E[f(B_t)1(B_t > a)]
+ E[f(2a - B_t)1(B_t > a)]
\end{eqnarray*}
\end{proof}
\begin{theorem}{Girsanov}
If $(B_t)_{t\ge0}$ is Brownian motion under the measure $P$, then
$(B_t - \theta t)_{t\ge0}$ is Brownian motion under the measure
$Q$ where $\frac{dQ|_{\F_t}}{dP|_{\F_t}} = e^{\theta B_t - \theta^2 t/2}$.
\end{theorem}

\subsection{It\=o Integrals}

Let $(B_t)_{t\ge0}$ be standard Brownian motion on $\Omega = C[0,\infty)$,
$\F_t$ the smallest $\sigma$-algebra for which $\{B_s:s\le t\}$ are
measurable, and $P$ be Wiener measure.  For $\theta\colon [0,\infty)\times
\Omega\to\R$ measurable with $\omega\mapsto\theta(t,\omega)$ $\F_t$
measurable ({\em adapted}) and $t\mapsto\theta(t, \omega)$ continuous, define
\begin{equation*}
\int_0^t \theta(s,\omega)\,dB_s(\omega)
	= \lim_{\Delta t\to 0} \sum_{j = 0}^{n - 1} \theta(t_j, \omega)
	(B_{t_{j+1}}(\omega) - B_{t_j}(\omega)),
\end{equation*}
where the limit is with respect
to the net of finite partitions of $[0,t]$ ordered by inclusion
and convergence is in probability. Note the left endpoint is used
when evaluating the integrand.

%What class of integrands? 
%$\sigma$-algebra generated by the simple functions are {\em predictably
%measurable processes}.
%Can be extended to jointly measurable non-anticipating processes. (K. L. Chung and R. Williams)

%Stratonovich. Allows ``proper'' definition of $X\,dX$ even for discountinuous $X$. (Herman Rubin.
%D.L. Fisk PhD thesis)

\subsection{It\=o Processes}
The solution of the SDE $dX_t = \mu\,dt + \sigma\,dB_t$, $X_{t_0} = x_0$
for $\mu$ and $\sigma$ measurable, adapted, and continuous is given by
\begin{equation*}
X_t(\omega) = x_0 + \int_{t_0}^t \mu(s, \omega)\,ds
	+ \int_{t_0}^t \sigma(s, \omega)\,dB_s(\omega),
\end{equation*}
where the first integral is a Riemann integral and the second is
the It\=o integral. The solution is called an {\em It\=o process}.
The $\mu$ term is the {\em drift} and $\sigma$ is the
{\em volatility} or {\em dispersion}.

\subsection{It\=o Diffusions}
An It\=o diffusion is a stochastic process, $(X_t)_{t\ge0}$ that
satisfies a SDE of the form $dX_t = \mu(t, X_t)\,dt + \sigma(t, X_t)\,dB$
where $\mu$ and $\sigma$ are Lipschitz continuous.
More explicitly, if $X_{t_0} = x_0$ is the initial condition, then
\begin{equation*}
X_t(\omega) = x_0 + \int_{t_0}^t \mu(s, X_s(\omega))\,ds
	+ \int_{t_0}^t \sigma(s, X_s(\omega))\,dB_s(\omega)
\end{equation*}
Note $\mu$, $\sigma\colon [0,\infty)\times\R\to\R$ and if
$(X_t)_{t\ge0}$ is adapted then $\omega\to\mu(t, X_t(\omega))$
is $\F_t$ measurable.

Oksendal (chapter 7) assumes $\mu$ and $\sigma$ do not depend on $t$.
He works with multi-dimensional Brownian motion and special
cases the time dimension as a diffusion with drift 1 and
dispersion 0.

\subsection{It\=o's Lemma}
If $dX = \mu\,dt + \sigma\,dB$ is an It\=o diffusion and
$f\colon [0,\infty)\times\R\to\R$ has one continuous
derivative in the first variable and two continuous derivatives
in the second, then
$Y_t = f(t, X_t)$ is also an It\=o diffusion and
satisfies the SDE
\begin{eqnarray*}
dY_t &=& 
	(f_t(t, X_t) + \mu f_x(t, X_t) + \frac{1}{2}\sigma^2 f_{xx}(t, X_t))\,dt + \sigma f_x(t, X_t)\,dB_t
\end{eqnarray*}

One can use the It\=o calculus to informally derive this.  If we let $Y =
f(t, X)$ then $dY = f_t\,dt +  f_x\,dX + (1/2)f_{xx}\,(dX)^2
= f_t\,dt +  f_x\,(\mu\,dt + \sigma\,dB) + (1/2)f_{xx}\,\sigma^2\,dt
= (f_t + f_x\mu + (1/2)f_{xx}\sigma^2)dt + f_x\sigma\,dB$.

More explicitly, $dY = \nu\,dt + \tau\,dB$ where
$\nu(t, y) = D_1f(t, y) + \mu(t, y)D_2f(t, y)
+ (1/2)\sigma^2(t, y)D_{22}f(t,y)$
and $\tau(t, y) = \sigma(t, y)D_2 f(t, y)$, where $D_jf$ denotes
the derivative with respect to the $j$-th argument of $f$.

\subsection{Generator of a Diffusion}
The {\em generator} of an It\=o diffusion is a linear operator
defined on functions $f\colon\R\to\R$ by
\begin{equation*}
\A f(x) = \lim_{t\downarrow 0}\frac{E^x[f(X_t)] - f(x)}{t}.
\end{equation*}
If $f$ is twice differentiable, it can be shown
$\A f = \mu f' + (1/2)\sigma^2 f''$

\subsection{Dynkin Formula and Kolmogorov Backward Equation}
If $T$ is a stopping time, Dynkin's formula is
$E^x[f(X_T)] = f(x) + E^x[\int_0^T\A
f(X_t)\,dt]$.  A simple consequence of this is the Kolmogorov
backward equation. If we define $v(t, x)
= E^x[f(X_t)]$ then $v_t = \mu v_x + (1/2)\sigma^2 v_{xx}$. Note $v(0,
x) = f(x)$. This shows the connection between SDE's
and PDE's.


%$E^x[f(X_{t+dt}) - f(X_t)] = E^x[f'(

\section{Remarks}
Meyer \cite{Mey1966}, p. 68, proves the difficult result that every
measurable and adapted stochastic process has a progressively measurable
modification. A much simpler fact is that every adapted stochastic
process having right-continuous (or left-continuous) sample paths is
progressively measurable.

\section{References}

[1] Oksendal, Bernt K. (2007),
{\it Stochastic Differential Equations: An Introduction with Applications.}
Berlin: Springer. 

[2] Protter, Philip E. (2004),
{\it Stochastic Integration and Differential Equations (2nd ed.)}
Springer.

